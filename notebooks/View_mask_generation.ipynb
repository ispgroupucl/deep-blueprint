{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57ed73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import skimage\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize\n",
    "\n",
    "# %matplotlib notebook\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "187c5f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5991\n",
      "5991\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"/globalscratch/users/n/s/nsayez/deepsun_bioblue/All\"\n",
    "# seg_types = ['LTH_UnsupervisedLonePenumbra']\n",
    "seg_types = ['LTH_LonePenumbraIsBg']\n",
    "\n",
    "image_folder     = os.path.join(dataset_root, 'image')\n",
    "# gt_folder        = os.path.join(dataset_root, 'GroundTruth')\n",
    "generated_folders = {t : os.path.join(dataset_root, t) for t in seg_types}\n",
    "\n",
    "image_lst = sorted(glob.glob(os.path.join(image_folder, '**/*.FTS'), recursive=True))\n",
    "\n",
    "generated_lsts = {t : sorted(glob.glob(os.path.join(generated_folders[t], '*.png'))) for t in seg_types}\n",
    "\n",
    "print(len(image_lst))\n",
    "# print(len(generated_lsts['LTH_UnsupervisedLonePenumbra']))\n",
    "print(len(generated_lsts['LTH_LonePenumbraIsBg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f7f69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in seg_types:\n",
    "    \n",
    "    for img in generated_lsts[t]:\n",
    "        if os.path.basename(img).startswith('UCC'):\n",
    "            os.remove(img)\n",
    "\n",
    "# print(len(generated_lsts['LTH_LonePenumbraIsBg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74675051",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint16\n",
      "uint8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9a6bd2bb7d44b5b5f226657216b4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=0, description='Image Index', max=5990), Checkbox(value=True, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_idx = len(image_lst)\n",
    "\n",
    "cmap_gen = cm.turbo\n",
    "# cmap_pred = cm.cool\n",
    "cmap_gen = cmap_gen(range(255))\n",
    "cmap_gen = ListedColormap([(0, 0, 0, 0), *cmap_gen])\n",
    "\n",
    "cmap_gt = cm.autumn\n",
    "cmap_gt = cmap_gt(range(255))\n",
    "cmap_gt = ListedColormap([(0, 0, 0, 0), *cmap_gt])\n",
    "\n",
    "\n",
    "def refresh(slider): \n",
    "    xlims0 = axes0[0].get_xlim()\n",
    "    ylims0 = axes0[0].get_ylim()\n",
    "    \n",
    "    axes0[0].clear()\n",
    "    \n",
    "    test_img = imread(image_lst[idx_slider.value])\n",
    "#     gt_label = imread(gt_lst[idx_slider.value])\n",
    "#     gen_label = imread(generated_lst[idx_slider.value])\n",
    "    \n",
    "    if img_cb.value:\n",
    "        axes0[0].imshow(test_img, cmap=\"gray\", interpolation=\"None\")\n",
    "#         axes0[0].invert_yaxis()\n",
    "        axes0[0].get_xlim()[::-1]\n",
    "    if gt_cb.value:\n",
    "        axes0[0].imshow(gt_label, cmap=cmap_gt, interpolation=\"None\", alpha=.5)\n",
    "    for i, cb in enumerate(gen_cbs):\n",
    "        if cb.value:\n",
    "            tmp = imread(generated_lsts[seg_types[i]][idx_slider.value])\n",
    "            cs = axes0[0].imshow(tmp, cmap=cmap_gen, interpolation=\"None\", alpha=.5)\n",
    "        \n",
    "    if xlims0 != (0.0, 1.0):\n",
    "        axes0[0].set_xlim(xlims0)\n",
    "        axes0[0].set_ylim(ylims0)\n",
    "    return\n",
    "\n",
    "max_rows = 1\n",
    "max_cols = 1\n",
    "\n",
    "plt.ioff()\n",
    "plt.style.use('default')\n",
    "# plt.style.use('dark_background')\n",
    "fig_widget0, axes0 = plt.subplots(nrows=max_rows, ncols=max_cols, figsize=(8,5))\n",
    "\n",
    "try:\n",
    "    len(axes0)\n",
    "except TypeError:\n",
    "    axes0 = [axes0]\n",
    "\n",
    "plt.ion()\n",
    "img_cb = widgets.Checkbox(value=True, description='Show img')\n",
    "gt_cb = widgets.Checkbox(value=False, description='Show gt')\n",
    "# ann_cbs = [widgets.Checkbox(value=False, description=f'Show {exp}') for exp in experts ]\n",
    "gen_cbs = [widgets.Checkbox(value=False, description=f'Show {t}') for t in seg_types]\n",
    "# gen_cb = widgets.Checkbox(value=False, description='Show Generation')\n",
    "idx_slider = widgets.IntSlider(value=0, min=0, max=max_idx-1, step=1, description=\"Image Index\")\n",
    "\n",
    "\n",
    "# Input image to predict\n",
    "test_img = imread(image_lst[0])\n",
    "#prediction\n",
    "gen_label = imread(generated_lsts[seg_types[0]][0])\n",
    "\n",
    "\n",
    "print(test_img.dtype)\n",
    "print(gen_label.dtype)\n",
    "\n",
    "axes0[0].imshow(test_img, cmap=\"gray\", interpolation=\"None\")\n",
    "\n",
    "fig_widget0.colorbar(cm.ScalarMappable(norm=Normalize(vmin=0, vmax=3, clip=False), cmap=cmap_gen), ax=axes0)\n",
    "# fig_widget0.colorbar(cs)\n",
    "\n",
    "img_cb.observe(refresh, names='value')\n",
    "gt_cb.observe(refresh, names='value')\n",
    "for cb in gen_cbs:\n",
    "    cb.observe(refresh, names='value')\n",
    "# gen_cb.observe(refresh, names='value')\n",
    "idx_slider.observe(refresh, names='value')\n",
    "\n",
    "\n",
    "widgets.VBox([widgets.HBox([idx_slider, img_cb]+gen_cbs), fig_widget0.canvas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bbbf2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/globalscratch/users/n/s/nsayez/deepsun_bioblue/All/image/2013/01/UPH20130101133418.FTS\n"
     ]
    }
   ],
   "source": [
    "print(image_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b680a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes0[0].invert_yaxis()\n",
    "axes0[0].set_ylim([1125,1325])\n",
    "axes0[0].set_xlim([630,1025])\n",
    "cmap_pred = cm.turbo\n",
    "# cmap_pred = cm.cool\n",
    "cmap_pred = cmap_pred(range(255))\n",
    "cmap_pred = ListedColormap([(0, 0, 0, 0), *cmap_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1c84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np \n",
    "\n",
    "\n",
    "# # PyTroch version\n",
    "\n",
    "# SMOOTH = 1e-6\n",
    "\n",
    "# def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "#     # You can comment out this line if you are passing tensors of equal shape\n",
    "#     # But if you are passing output from UNet or something it will most probably\n",
    "#     # be with the BATCH x 1 x H x W shape\n",
    "#     outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    \n",
    "#     intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "#     union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
    "    \n",
    "#     iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    \n",
    "#     thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    \n",
    "#     return thresholded  # Or thresholded.mean() if you are interested in average across the batch\n",
    "    \n",
    "    \n",
    "# # Numpy version\n",
    "# # Well, it's the same function, so I'm going to omit the comments\n",
    "\n",
    "# def iou_numpy(outputs: np.array, labels: np.array):\n",
    "#     outputs = outputs.squeeze(1)\n",
    "    \n",
    "#     intersection = (outputs & labels).sum((1, 2))\n",
    "#     union = (outputs | labels).sum((1, 2))\n",
    "    \n",
    "#     iou = (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    \n",
    "#     thresholded = np.ceil(np.clip(20 * (iou - 0.5), 0, 10)) / 10\n",
    "    \n",
    "#     return thresholded  # Or thresholded.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6386640",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26350/3884453854.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnp_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(np_array.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgt_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtot_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# build tensor for the whole reference set\n",
    "gt_tensors = [] \n",
    "for i, path in enumerate(gt_lst[:]):\n",
    "    np_array = np.array(imread(path))\n",
    "#     print(np_array.shape)\n",
    "    gt_tensors.append( torch.unsqueeze(torch.from_numpy(np_array), axis=0))\n",
    "    \n",
    "tot_gt = torch.cat(gt_tensors)\n",
    "print(tot_gt.shape)\n",
    "\n",
    "LTH_tensors = [] \n",
    "for i, path in enumerate(generated_lsts['LocalTopHat'][:]):\n",
    "    np_array = np.array(imread(path))\n",
    "#     print(np_array.shape)\n",
    "    LTH_tensors.append( torch.unsqueeze(torch.from_numpy(np_array.astype(np.uint8)), axis=0))\n",
    "\n",
    "tot_LTH = torch.cat(LTH_tensors)\n",
    "print(tot_LTH.shape)\n",
    "\n",
    "Grid_tensors = [] \n",
    "for i, path in enumerate(generated_lsts['Grid'][:]):\n",
    "    np_array = np.array(imread(path))\n",
    "#     print(np_array.shape)\n",
    "    Grid_tensors.append( torch.unsqueeze(torch.from_numpy(np_array.astype(np.uint8)), axis=0))\n",
    "\n",
    "tot_Grid = torch.cat(Grid_tensors)\n",
    "print(tot_Grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2ad1c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import ConfusionMatrix\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "\n",
    "class IoU(ConfusionMatrix):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        threshold: float = 0.5,\n",
    "        class_index: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            num_classes,\n",
    "            normalize=None,\n",
    "            threshold=threshold,\n",
    "            compute_on_step=True,\n",
    "            dist_sync_on_step=False,\n",
    "        )\n",
    "        self.class_index = class_index\n",
    "\n",
    "    def compute(self) -> torch.Tensor:\n",
    "        cm = super().compute().to(torch.double)\n",
    "        iou = cm.diag() / (cm.sum(dim=1) + cm.sum(dim=0) - cm.diag() + 1e-15)\n",
    "        if self.class_index is None:\n",
    "            return iou.mean()\n",
    "        else:\n",
    "            return iou[self.class_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2fcc0616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 36/36 [03:00<00:00,  5.02s/it]\n"
     ]
    }
   ],
   "source": [
    "LTH_ious = {'0':[], '1': [], '2':[] }\n",
    "for i in tqdm.tqdm(range(tot_gt.shape[0])):\n",
    "    for c in range(3):\n",
    "        iou = IoU(num_classes=3, class_index=c)\n",
    "        res = iou(tot_LTH[i,:,:], tot_gt[i,:,:])\n",
    "        LTH_ious[str(c)].append(res)\n",
    "#         print(f'class {c} -> {res}')\n",
    "# print(ious)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1304bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0.999660716157584, '1': 0.44184888613901757, '2': 0.3772279800360334}\n"
     ]
    }
   ],
   "source": [
    "LTH_mean_ious = {t: np.mean(LTH_ious[t]) for t in LTH_ious.keys()}\n",
    "print(LTH_mean_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6a92a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████▌                           | 18/36 [00:30<00:30,  1.69s/it]/home/ucl/elen/nsayez/miniconda3/envs/A100-bioblue/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: 3 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "100%|███████████████████████████████████████████████████████| 36/36 [01:00<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "# CMs are shaped [target_classes X pred_classes]\n",
    "LTH_cms = []\n",
    "# for i in tqdm.tqdm(range(2)):\n",
    "for i in tqdm.tqdm(range(tot_gt.shape[0])):\n",
    "    LTH_cm = ConfusionMatrix(num_classes=3, normalize='true')\n",
    "    LTH_cm(tot_LTH[i,:,:], tot_gt[i,:,:]).to('cuda:0')\n",
    "    cm = LTH_cm.compute()\n",
    "#     print(cm)\n",
    "#     print((cm.sum(dim=1) + cm.sum(dim=0) - cm.diag()).sum() )\n",
    "    LTH_cms.append(cm)\n",
    "    \n",
    "LTH_cms = [torch.unsqueeze(item, 0) for item in LTH_cms.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "60616f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n",
      "torch.Size([36, 3, 3])\n",
      "[['99.995', '0.005', '0.000'], ['42.190', '48.376', '9.433'], ['25.666', '14.588', '56.968']]\n"
     ]
    }
   ],
   "source": [
    "print(LTH_cms[1].shape)\n",
    "tot_LTH_CM = torch.cat(LTH_cms)\n",
    "print(tot_LTH_CM.shape)\n",
    "mean_LTH_CM = torch.mean(100*tot_LTH_CM,0)\n",
    "std_LTH_CM = torch.std(100*tot_LTH_CM,0)\n",
    "# print(mean_LTH_CM)\n",
    "# print(std_LTH_CM)\n",
    "\n",
    "LTH_CM_percents = [[0,0,0],[0,0,0],[0,0,0]]\n",
    "for i in range(mean_LTH_CM.shape[0]):\n",
    "#     print(i)\n",
    "    for j in range(mean_LTH_CM.shape[1]):\n",
    "#         print(j)\n",
    "        LTH_CM_percents[i][j] = '{:.3f}'.format(mean_LTH_CM[i,j])\n",
    "    \n",
    "print(LTH_CM_percents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac40a4d",
   "metadata": {},
   "source": [
    "GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5dc74c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 36/36 [01:00<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# CMs are shaped [target_classes X pred_classes]\n",
    "Grid_cms = []\n",
    "# for i in tqdm.tqdm(range(2)):\n",
    "for i in tqdm.tqdm(range(tot_gt.shape[0])):\n",
    "    Grid_cm = ConfusionMatrix(num_classes=3, normalize='true')\n",
    "    Grid_cm(tot_Grid[i,:,:], tot_gt[i,:,:]).to('cuda:0')\n",
    "    cm = Grid_cm.compute()\n",
    "#     print(cm)\n",
    "#     print((cm.sum(dim=1) + cm.sum(dim=0) - cm.diag()).sum() )\n",
    "    Grid_cms.append(cm)\n",
    "    \n",
    "Grid_cms = [torch.unsqueeze(item, 0) for item in Grid_cms.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c016c4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n",
      "torch.Size([36, 3, 3])\n",
      "[['99.968', '0.032', '0.000'], ['24.096', '56.569', '19.335'], ['12.714', '25.996', '58.512']]\n"
     ]
    }
   ],
   "source": [
    "print(Grid_cms[1].shape)\n",
    "tot_Grid_CM = torch.cat(Grid_cms)\n",
    "print(tot_Grid_CM.shape)\n",
    "mean_Grid_CM = torch.mean(100*tot_Grid_CM,0)\n",
    "std_Grid_CM = torch.std(100*tot_Grid_CM,0)\n",
    "# print(mean_Grid_CM)\n",
    "# print(std_Grid_CM)\n",
    "\n",
    "Grid_CM_percents = [[0,0,0],[0,0,0],[0,0,0]]\n",
    "for i in range(mean_Grid_CM.shape[0]):\n",
    "#     print(i)\n",
    "    for j in range(mean_Grid_CM.shape[1]):\n",
    "#         print(j)\n",
    "        Grid_CM_percents[i][j] = '{:.3f}'.format(mean_Grid_CM[i,j])\n",
    "    \n",
    "print(Grid_CM_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "21cde309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 36/36 [02:59<00:00,  5.00s/it]\n"
     ]
    }
   ],
   "source": [
    "Grid_ious = {'0':[], '1': [], '2':[] }\n",
    "for i in tqdm.tqdm(range(tot_gt.shape[0])):\n",
    "    for c in range(3):\n",
    "        iou = IoU(num_classes=3, class_index=c)\n",
    "        res = iou(tot_Grid[i,:,:], tot_gt[i,:,:])\n",
    "        Grid_ious[str(c)].append(res)\n",
    "#         print(f'class {c} -> {res}')\n",
    "# print(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "95094d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0.9995164164985033, '1': 0.36687629560801466, '2': 0.28443676916901955}\n"
     ]
    }
   ],
   "source": [
    "Grid_mean_ious = {t: np.mean(Grid_ious[t]) for t in Grid_ious.keys()}\n",
    "print(Grid_mean_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac912ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
